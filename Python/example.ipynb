{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc0d85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from customdataset import *\n",
    "from SSD import *\n",
    "from VIT import *\n",
    "from train_step import *\n",
    "from eval_step import test_step\n",
    "import os\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47db1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 8000\n",
    "HOP_LENGTH = int(np.ceil(SAMPLE_RATE*0.01))#시간\n",
    "WIN_LENGTH = int(np.ceil(SAMPLE_RATE / 15))#주파수\n",
    "_length = WIN_LENGTH - 1\n",
    "\n",
    "n=0\n",
    "while _length > 1:\n",
    "    _length = _length // 2\n",
    "    n+=1\n",
    "N_FFT = 2 ** (n+1)\n",
    "N_MELS = 128 \n",
    "\n",
    "print(SAMPLE_RATE, HOP_LENGTH, WIN_LENGTH, N_FFT, N_MELS)\n",
    "\n",
    "filters = [\n",
    "    (Biquad.LOWPASS, 400, SAMPLE_RATE, 1.0),\n",
    "    (Biquad.HIGHPASS, 25, SAMPLE_RATE, 1.0),\n",
    "    (Biquad.BANDPASS, 125, SAMPLE_RATE, 1.0),\n",
    "    (Biquad.PEAK, 125, SAMPLE_RATE, 1.0),\n",
    "    (Biquad.NOTCH, 125, SAMPLE_RATE, 1.0, 1.0),\n",
    "    (Biquad.LOWSHELF, 200, SAMPLE_RATE, 1.0, 1.0),\n",
    "    (Biquad.HIGHSHELF, 125, SAMPLE_RATE, 1.0, 1.0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95da51f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "args={\"SR\" : SAMPLE_RATE,\n",
    "      \"HL\" : HOP_LENGTH,\n",
    "      \"WL\" : WIN_LENGTH,\n",
    "      \"n_FFT\" : N_FFT,\n",
    "      \"n_MELS\" : N_MELS,\n",
    "      \n",
    "      \"augmentation\" : False, #False or True    If using True: data size * 4\n",
    "      \"filter_params\" : [filters[1],filters[0]], # not using : []\n",
    "      \"padding_type\" : 0, # 0: simply pad by zeros 1: pad with duplicate on both sides \n",
    "      \"freq_mask\" : False, # False or (probability that the mask will be applied, size of the mask's area (percentage of the image))\n",
    "      \"time_mask\" : (0.1, 0.05, False) # False or (p, ratio, label existence and nonexistence)\n",
    "      \"multi_channels\" : False, # True : 1channel image,  False : 3channel image\n",
    "      \"clipping\" : True,\n",
    "      \"target_size\" : (300, 300),\n",
    "      \"th\" : 5, # audio split size\n",
    "      \"wandb_project_name\" : \"Heart_Signal_Detection_channel\",\n",
    "      \"wandb_entity\" : \"heart-signel-det\",\n",
    "      \"cutting\": True,\n",
    "      \n",
    "      \"MODEL_NAME\" : \"MnetSSD\", #Mnet or ViT\n",
    "      \"is_pretrain\" : False,\n",
    "      \"is_freeze\" : False,\n",
    "      \"epoch_num\" : 60,\n",
    "      \"batch_size\" : 8,\n",
    "      \"min_lr\" : 1e-4,\n",
    "      \"max_lr\" : 2e-3,\n",
    "      \"alpha\" : 1, # loss = conf_loss + alpha * Loc_Loss\n",
    "      \"optim_type\" : \"Adam\", #SGD or Adam\n",
    "      \n",
    "      \"conf_thresh\" : 0.4,\n",
    "      \"nms_thresh\" : 0.5, \n",
    "      \"iou_thresh\" : 0.5\n",
    "     }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569c2e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH="{your_Path}/physionet.org/files/circor-heart-sound/1.0.3/training_data\"\n # DataPath",
    "file_list = os.listdir(PATH)\n",
    "txt_list = [os.path.join(PATH, file) for file in file_list if file.endswith(\".txt\")]\n",
    "\n",
    "# 환자 아이디를 훈련, 검증, 테스트 데이터셋으로 나눔\n",
    "train_patient_txt, extra_patient_txt = train_test_split(txt_list, test_size=0.4, random_state=42)\n",
    "valid_patient_txt, test_patient_txt = train_test_split(extra_patient_txt, test_size=0.5, random_state=42)\n",
    "\n",
    "print(len(txt_list) ,len(train_patient_txt),\n",
    "      len(valid_patient_txt) ,len(test_patient_txt)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713e8c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_patient_txt[0]) \n",
    "test_patient_txt=[test_patient_txt[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172a2351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate_fn(batch):\n",
    "    targets = []\n",
    "    imgs = []\n",
    "    for sample in batch:\n",
    "        imgs.append(sample[0])  # sample[0]은 화상 gt\n",
    "        targets.append(torch.FloatTensor(sample[1]))  # sample[1]은 어노테이션 gt\n",
    "\n",
    "    imgs = torch.stack(imgs, dim=0)\n",
    "    return imgs, targets\n",
    "BATCHSIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603b5d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s_t=time.time()\n",
    "\n",
    "dataset = CustomDataset(PATH, train_patient_txt,\n",
    "                        sample_rate = args['SR'],\n",
    "                        hop_length = args['HL'],\n",
    "                        n_mels = args['n_MELS'],\n",
    "                        n_fft = args['n_FFT'],\n",
    "                        win_length = args['WL'],\n",
    "                        time_mask = args[\"time_mask\"],\n",
    "                        delete_label = args[\"cutting\"],\n",
    "                        filter_params = args[\"filter_params\"], \n",
    "                        padding_type = args[\"padding_type\"], clipping = args[\"clipping\"], \n",
    "                        target_size = args[\"target_size\"], th = args[\"th\"])\n",
    "train_dataloader = DataLoader(dataset, batch_size=BATCHSIZE, shuffle=True, collate_fn=my_collate_fn)\n",
    "e_t=time.time()\n",
    "\n",
    "print(e_t-s_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bf5ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_t=time.time()\n",
    "dataset = CustomDataset(PATH, valid_patient_txt,\n",
    "                        sample_rate = args['SR'],\n",
    "                        hop_length = args['HL'],\n",
    "                        n_mels = args['n_MELS'],\n",
    "                        n_fft = args['n_FFT'],\n",
    "                        win_length = args['WL'],\n",
    "                        delete_label = args[\"cutting\"],\n",
    "                        filter_params = args[\"filter_params\"], \n",
    "                        padding_type = args[\"padding_type\"], clipping = args[\"clipping\"], \n",
    "                        target_size = args[\"target_size\"], th = args[\"th\"])\n",
    "valid_dataloader = DataLoader(dataset, batch_size=BATCHSIZE, shuffle=True, collate_fn=my_collate_fn)\n",
    "e_t=time.time()\n",
    "\n",
    "print(e_t-s_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd97abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_t=time.time()\n",
    "dataset = CustomDataset(PATH, test_patient_txt,\n",
    "                        sample_rate = args['SR'],\n",
    "                        hop_length = args['HL'],\n",
    "                        n_mels = args['n_MELS'],\n",
    "                        n_fft = args['n_FFT'],\n",
    "                        win_length = args['WL'],\n",
    "                        delete_label = False,\n",
    "                        filter_params = args[\"filter_params\"], \n",
    "                        padding_type = args[\"padding_type\"], clipping = args[\"clipping\"], \n",
    "                        target_size = args[\"target_size\"], th = args[\"th\"])\n",
    "test_dataloader = DataLoader(dataset, batch_size=BATCHSIZE, shuffle=False, collate_fn=my_collate_fn)\n",
    "e_t=time.time()\n",
    "\n",
    "print(e_t-s_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9907a157",
   "metadata": {},
   "source": [
    "# build_model (ssd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263201e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "model = build_model_SSD(\"Train\", input_channels=1, is_freeze=args[\"is_freeze\"], is_pretrain=args[\"is_pretrain\"])\n",
    "test_model =  build_model_SSD(\"Test\", input_channels=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3ff2a1",
   "metadata": {},
   "source": [
    "# build_model(vit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cbe7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = VIT_Det(in_channels=1, n_class=3, default_box_n=8, depth=1, state = \"Train\")\n",
    "test_model = VIT_Det(in_channels=1, n_class=3, default_box_n=8, depth=1, state = \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27181cda",
   "metadata": {},
   "source": [
    "# train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb693538",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args[\"MODEL_NAME\"] == \"MnetSSD\":\n",
    "    d=default()\n",
    "    tensor_d = d.forward()\n",
    "    \n",
    "elif args[\"MODEL_NAME\"] == \"ViT\":\n",
    "    d=default(feature_maps=[19] ,aspect_ratios=[[2,3,4]])\n",
    "    tensor_d = d.forward(args[\"MODEL_NAME\"])\n",
    "\n",
    "train_step(model, test_model, train_dataloader, valid_dataloader, tensor_d, args,is_wandb=True, device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c212e0d",
   "metadata": {},
   "source": [
    "# test_step (ssd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a712ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = build_model_SSD(\"Test\", input_channels=1)\n",
    "model_weight_path='./objectdetection_model/{model_name}' # your model path \n",
    "weight = torch.load(model_weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbf5d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(weight)\n",
    "model.eval()\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc1eff6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if args[\"MODEL_NAME\"] == \"MnetSSD\":\n",
    "    d=default()\n",
    "    tensor_d = d.forward()\n",
    "    \n",
    "elif args[\"MODEL_NAME\"] == \"ViT\":\n",
    "    d=default(feature_maps=[19] ,aspect_ratios=[[2,3,4,5]])\n",
    "    tensor_d = d.forward(args[\"MODEL_NAME\"])\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "s = time.time()\n",
    "result = test_step(model, test_dataloader, tensor_d, image_size=(300,300), device = DEVICE, iou_threshold=0.5)\n",
    "e = time.time()\n",
    "print(e-s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dc2d72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(result) #(total_Recall, S1_Recall, S2_Recall,total_Precison, S2_Recall, S2_Precison, mAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9a18f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_step(model, test_dataloader, tensor_d, device = DEVICE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

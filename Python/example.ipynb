{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c68a8868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from customdataset import CustomDataset\n",
    "from SSD import *\n",
    "from train_step import train_step\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e98f5918",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=os.getenv(\"HOME\")+\"/aiffel/ECG_data/physionet.org/files/circor-heart-sound/1.0.3/training_data\"\n",
    "file_list = os.listdir(PATH)\n",
    "txt_list = [os.path.join(PATH, file) for file in file_list if file.endswith(\".txt\")]\n",
    "\n",
    "# 환자 아이디를 훈련 데이터셋과 테스트 데이터셋으로 나눔\n",
    "train_patient_txt, test_patient_txt = train_test_split(txt_list, test_size=0.9, random_state=42)\n",
    "\n",
    "# 결과 출력\n",
    "#print(\"Train Patient IDs:\", train_patient_txt[:1])\n",
    "#print(\"Test Patient IDs:\", test_patient_txt[:1])\n",
    "\n",
    "#path, txt_list, filter_params, target_size, th, resizing\n",
    "dataset = CustomDataset(PATH, train_patient_txt, target_size=(300, 300), th=5, resizing=True)\n",
    "\n",
    "\n",
    "def my_collate_fn(batch):\n",
    "    targets = []\n",
    "    imgs = []\n",
    "    for sample in batch:\n",
    "        imgs.append(sample[0])  # sample[0]은 화상 gt\n",
    "        targets.append(torch.FloatTensor(sample[1]))  # sample[1]은 어노테이션 gt\n",
    "\n",
    "    imgs = torch.stack(imgs, dim=0)\n",
    "    return imgs, targets\n",
    "BATCHSIZE = 8\n",
    "train_dataloader = DataLoader(dataset, batch_size=BATCHSIZE, shuffle=True, collate_fn=my_collate_fn)\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2f18be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\"Train\", input_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d78c70eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 / 2\n",
      "Current Batch 0 / 131 | Cls Loss : 6.394, Loc Loss : 7.959, Total Loss : 14.354 | 10 iter time 0.1480: \n",
      "Current Batch 50 / 131 | Cls Loss : 3.196, Loc Loss : 4.636, Total Loss : 7.832 | 10 iter time 3.2312: \n",
      "Current Batch 100 / 131 | Cls Loss : 2.898, Loc Loss : 4.712, Total Loss : 7.610 | 10 iter time 3.1695: \n",
      "Epoch : 1 / 2 of Total Loss : Total Loss : 1010.949 | 1 epoch update time : 8.50s\n",
      "-----------------------------------------------\n",
      "Already './objectdetection_model' DIR path\n",
      "Epoch : 2 / 2\n",
      "Current Batch 0 / 131 | Cls Loss : 3.026, Loc Loss : 4.876, Total Loss : 7.902 | 10 iter time 0.0595: \n",
      "Current Batch 50 / 131 | Cls Loss : 3.004, Loc Loss : 4.916, Total Loss : 7.921 | 10 iter time 3.1870: \n",
      "Current Batch 100 / 131 | Cls Loss : 2.463, Loc Loss : 4.187, Total Loss : 6.650 | 10 iter time 3.1484: \n",
      "Epoch : 2 / 2 of Total Loss : Total Loss : 915.579 | 1 epoch update time : 8.32s\n",
      "-----------------------------------------------\n",
      "Already './objectdetection_model' DIR path\n"
     ]
    }
   ],
   "source": [
    "train_step(model, train_dataloader,epoch_num = 2, batchsize=BATCHSIZE, is_wandb=False, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3ab46e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f5ff58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from customdataset import *\n",
    "from SSD import *\n",
    "from train_step import *\n",
    "from eval_step import test_step\n",
    "import os\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2931e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 8000\n",
    "HOP_LENGTH = int(np.ceil(SAMPLE_RATE*0.01))#시간\n",
    "WIN_LENGTH = int(np.ceil(SAMPLE_RATE / 15))#주파수\n",
    "_length = WIN_LENGTH - 1\n",
    "\n",
    "n=0\n",
    "while _length > 1:\n",
    "    _length = _length // 2\n",
    "    n+=1\n",
    "N_FFT = 2 ** (n+1)\n",
    "N_MELS = 128 #300 if N_FFT // 2 + 1 > 300 else N_FFT // 2 + 1\n",
    "\n",
    "print(SAMPLE_RATE, HOP_LENGTH, WIN_LENGTH, N_FFT, N_MELS)\n",
    "\n",
    "filters = [\n",
    "    (Biquad.LOWPASS, 400, SAMPLE_RATE, 1.0),\n",
    "    (Biquad.HIGHPASS, 25, SAMPLE_RATE, 1.0),\n",
    "    (Biquad.BANDPASS, 125, SAMPLE_RATE, 1.0),\n",
    "    (Biquad.PEAK, 125, SAMPLE_RATE, 1.0),\n",
    "    (Biquad.NOTCH, 125, SAMPLE_RATE, 1.0, 1.0),\n",
    "    (Biquad.LOWSHELF, 200, SAMPLE_RATE, 1.0, 1.0),\n",
    "    (Biquad.HIGHSHELF, 125, SAMPLE_RATE, 1.0, 1.0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46f47d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "args={\"SR\" : SAMPLE_RATE,\n",
    "      \"HL\" : HOP_LENGTH,\n",
    "      \"WL\" : WIN_LENGTH,\n",
    "      \"n_FFT\" : N_FFT,\n",
    "      \"n_MELS\" : N_MELS,\n",
    "      \n",
    "      \"augmentation\" : False,\n",
    "      \"filter_params\" : [filters[1], filters[0]],\n",
    "      \"padding_type\" : 0,\n",
    "      \"freq_mask\" : False,\n",
    "      \"time_mask\" : False,\n",
    "      \"multi_channels\" : False,\n",
    "      \"clipping\" : True,\n",
    "      \"target_size\" : (300, 300),\n",
    "      \"th\" : 5,\n",
    "      \"cutting\": True,\n",
    "      \n",
    "      \"MODEL_NAME\" : \"MnetSSD\",\n",
    "      \"is_freeze\" : \"False\",\n",
    "      \"epoch_num\" : 100,\n",
    "      \"batch_size\" : 8,\n",
    "      \"min_lr\" : 1e-4,\n",
    "      \"max_lr\" : 2e-3,\n",
    "      \"optim_type\" : \"Adam\",\n",
    "      \n",
    "      \"conf_thresh\" : 0.6,\n",
    "      \"nms_thresh\" : 0.5, \n",
    "      \"iou_thresh\" : 0.7\n",
    "     }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e7855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=os.getenv(\"HOME\")+\"/aiffel/ECG_data/physionet.org/files/circor-heart-sound/1.0.3/training_data\"\n",
    "file_list = os.listdir(PATH)\n",
    "txt_list = [os.path.join(PATH, file) for file in file_list if file.endswith(\".txt\")]\n",
    "\n",
    "# 환자 아이디를 훈련, 검증, 테스트 데이터셋으로 나눔\n",
    "train_patient_txt, extra_patient_txt = train_test_split(txt_list, test_size=0.4, random_state=42)\n",
    "valid_patient_txt, test_patient_txt = train_test_split(extra_patient_txt, test_size=0.5, random_state=42)\n",
    "\n",
    "print(len(txt_list) ,len(train_patient_txt),\n",
    "      len(valid_patient_txt) ,len(test_patient_txt)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3109daa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(test_patient_txt[0]) \n",
    "#test_patient_txt=[test_patient_txt[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24801623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate_fn(batch):\n",
    "    targets = []\n",
    "    imgs = []\n",
    "    for sample in batch:\n",
    "        imgs.append(sample[0])  # sample[0]은 화상 gt\n",
    "        targets.append(torch.FloatTensor(sample[1]))  # sample[1]은 어노테이션 gt\n",
    "\n",
    "    imgs = torch.stack(imgs, dim=0)\n",
    "    return imgs, targets\n",
    "BATCHSIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeffa68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s_t=time.time()\n",
    "\n",
    "dataset = CustomDataset(PATH, train_patient_txt,\n",
    "                        sample_rate = args['SR'],\n",
    "                        hop_length = args['HL'],\n",
    "                        n_mels = args['n_MELS'],\n",
    "                        n_fft = args['n_FFT'],\n",
    "                        win_length = args['WL'],\n",
    "                        filter_params = args[\"filter_params\"], \n",
    "                        padding_type = args[\"padding_type\"], clipping = args[\"clipping\"], \n",
    "                        target_size = args[\"target_size\"], th = args[\"th\"])\n",
    "train_dataloader = DataLoader(dataset, batch_size=BATCHSIZE, shuffle=True, collate_fn=my_collate_fn)\n",
    "e_t=time.time()\n",
    "\n",
    "print(e_t-s_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e861671",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_t=time.time()\n",
    "dataset = CustomDataset(PATH, valid_patient_txt,\n",
    "                        sample_rate = args['SR'],\n",
    "                        hop_length = args['HL'],\n",
    "                        n_mels = args['n_MELS'],\n",
    "                        n_fft = args['n_FFT'],\n",
    "                        win_length = args['WL'],\n",
    "                        filter_params = args[\"filter_params\"], \n",
    "                        padding_type = args[\"padding_type\"], clipping = args[\"clipping\"], \n",
    "                        target_size = args[\"target_size\"], th = args[\"th\"])\n",
    "valid_dataloader = DataLoader(dataset, batch_size=BATCHSIZE, shuffle=True, collate_fn=my_collate_fn)\n",
    "e_t=time.time()\n",
    "\n",
    "print(e_t-s_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b846c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_t=time.time()\n",
    "dataset = CustomDataset(PATH, test_patient_txt,\n",
    "                        sample_rate = args['SR'],\n",
    "                        hop_length = args['HL'],\n",
    "                        n_mels = args['n_MELS'],\n",
    "                        n_fft = args['n_FFT'],\n",
    "                        win_length = args['WL'],\n",
    "                        filter_params = args[\"filter_params\"], \n",
    "                        padding_type = args[\"padding_type\"], clipping = args[\"clipping\"], \n",
    "                        target_size = args[\"target_size\"], th = args[\"th\"])\n",
    "test_dataloader = DataLoader(dataset, batch_size=BATCHSIZE, shuffle=False, collate_fn=my_collate_fn)\n",
    "e_t=time.time()\n",
    "\n",
    "print(e_t-s_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f80f548",
   "metadata": {},
   "source": [
    "# train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9f234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = build_model_SSD(\"Train\", input_channels=1, is_freeze=False)\n",
    "test_model =  build_model_SSD(\"Test\", input_channels=1)\n",
    "#model_weight_path='./objectdetection_model/ssd300_weight_100.pth'\n",
    "#weight = torch.load(model_weight_path)\n",
    "#model.load_state_dict(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24948970",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step(model, test_model, train_dataloader, valid_dataloader, args, is_wandb=True, device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4f7c55",
   "metadata": {},
   "source": [
    "# test_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e138a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = build_model_SSD(\"Test\", input_channels=1)\n",
    "model_weight_path='./objectdetection_model/MnetSSD_weight_101_8_Adam_False.pth'\n",
    "weight = torch.load(model_weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b86546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(weight)\n",
    "model.eval()\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355d3072",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "s = time.time()\n",
    "result = test_step(model, test_dataloader, image_size=(300,300), device = DEVICE)\n",
    "e = time.time()\n",
    "print(e-s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed1773a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(result) #(total_Recall, S1_Recall, S2_Recall,total_Precison, S2_Recall, S2_Precison, mAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe0e4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_step(model, test_dataloader, device = DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f047a1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze | grep -E \"torch\" >> requirements.txt\n",
    "!pip freeze | grep -E \"skimage\" >> requirements.txt\n",
    "!pip freeze | grep -E \"numpy\" >> requirements.txt\n",
    "!pip freeze | grep -E \"librosa\" >> requirements.txt\n",
    "!pip freeze | grep -E \"wandb\" >> requirements.txt\n",
    "!pip freeze | grep -E \"scipy\" >> requirements.txt\n",
    "!pip freeze | grep -E \"time\" >> requirements.txt\n",
    "!pip freeze | grep -E \"pandas\" >> requirements.txt\n",
    "!pip freeze | grep -E \"matplotlib\" >> requirements.txt\n",
    "!pip freeze | grep -E \"cmapy\" >> requirements.txt\n",
    "!pip freeze | grep -E \"nlpaug\" >> requirements.txt\n",
    "!pip freeze | grep -E \"wandb\" >> requirements.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

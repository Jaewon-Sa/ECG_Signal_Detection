{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64cbaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a7955d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9986b8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "#backbone = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True, progress = True)\n",
    "#backbone = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)\n",
    "#backbone= models.vgg19(pretrained=True).features.to(device)\n",
    "backbone = models.mobilenet_v3_large(pretrained=True)\n",
    "print(backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1776fb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "backbone.to(device)\n",
    "\n",
    "summary(backbone, input_size=(3, 300, 300), device=device.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bd3eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "class SSD(nn.Module):\n",
    "    def __init__(self, backbone, n_class=3, default_box_n=[4,6,6,6,4,4], state = \"Train\"):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_class = n_class\n",
    "        self.default_box_n = default_box_n\n",
    "        self.state = state\n",
    "        if self.state != \"Train\":\n",
    "            self.softmax = nn.Softmax(dim=-1)\n",
    "            \n",
    "        #가중치 초기화 인자\n",
    "        self.rescale_factors = nn.Parameter(torch.FloatTensor(1, 112, 1, 1))  # there are 512 channels in conv4_3_feats\n",
    "        nn.init.constant_(self.rescale_factors, 20)\n",
    "        \n",
    "        #backbone\n",
    "        #backbone.conv1.in_channels=1\n",
    "        self.backbone_layer = nn.Sequential(\n",
    "            backbone.features,\n",
    "        )\n",
    "        \n",
    "        #extra layer\n",
    "        self.extra_layer_1 = self.extra_layers(960,512,4)\n",
    "        self.extra_layer_2 = self.extra_layers(512,256,4)\n",
    "        self.extra_layer_3 = self.extra_layers(256,256,2)\n",
    "        self.extra_layer_4 = self.extra_layers(256,128,2)\n",
    "        \n",
    "        self.extra_layers = [self.extra_layer_1, \n",
    "                            self.extra_layer_2, \n",
    "                            self.extra_layer_3, \n",
    "                            self.extra_layer_4]\n",
    "        \n",
    "        \n",
    "        #detection output\n",
    "        \n",
    "        self.cls_layers = nn.ModuleList([\n",
    "                                        nn.Conv2d(672, default_box_n[0]*(self.n_class), kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "                                        nn.Conv2d(960, default_box_n[1]*(self.n_class), kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "                                        nn.Conv2d(512, default_box_n[2]*(self.n_class), kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "                                        nn.Conv2d(256, default_box_n[3]*(self.n_class), kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "                                        nn.Conv2d(256, default_box_n[4]*(self.n_class), kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "                                        nn.Conv2d(128, default_box_n[5]*(self.n_class), kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "                                        ])\n",
    "        \n",
    "        self.loc_layers = nn.ModuleList([\n",
    "                                        nn.Conv2d(672, default_box_n[0]*4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "                                        nn.Conv2d(960, default_box_n[1]*4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "                                        nn.Conv2d(512, default_box_n[2]*4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "                                        nn.Conv2d(256, default_box_n[3]*4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "                                        nn.Conv2d(256, default_box_n[4]*4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "                                        nn.Conv2d(128, default_box_n[5]*4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "                                        ])\n",
    "        \n",
    "        \n",
    "    \n",
    "    def init_conv2d(self):\n",
    "        #가중치 초기화 함수\n",
    "        \n",
    "        #모델학습이 순조롭지않다면 향후 추가 예정\n",
    "        return\n",
    "    \n",
    "    def extra_layers(self, input_size, output_size, div):\n",
    "        print(output_size/2)\n",
    "        layer = nn.Sequential(\n",
    "            #conv2D 해상도낮추기\n",
    "            nn.Conv2d(input_size, output_size, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
    "            nn.BatchNorm2d(output_size, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
    "            nn.Hardswish(),\n",
    "            \n",
    "            #Inverted Residual (mobilev2 + squeeze)\n",
    "            \n",
    "            #depthwise \n",
    "            # kernel size 5 고려해보기\n",
    "            nn.Conv2d(output_size, output_size, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=output_size, bias=False),\n",
    "            nn.BatchNorm2d(output_size, eps=0.001, momentum=0.01, affine=True, track_running_stats=True),\n",
    "            nn.Hardswish(),\n",
    "            \n",
    "            #SqueezeExcitation\n",
    "            nn.Conv2d(output_size, output_size//div, kernel_size=(1, 1), stride=(1, 1)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(output_size//div, output_size, kernel_size=(1, 1), stride=(1, 1)),\n",
    "            \n",
    "            #Point-wise\n",
    "            nn.Conv2d(output_size, output_size, kernel_size=(1, 1), stride=(1, 1)),\n",
    "            nn.Hardswish(),\n",
    "            nn.Identity()\n",
    "            \n",
    "        ) \n",
    "        return layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        f_maps=[]\n",
    "        for n, layer in enumerate(backbone.features):#12 16\n",
    "            if n==13: \n",
    "                #L2 norm\n",
    "                #norm = x.pow(2).sum(dim=1, keepdim=True).sqrt()     # (N, 1, 19, 19)\n",
    "                #featureMap_1 = x / norm                                  # (N, 112, 19, 19)\n",
    "                #featureMap_1= conv4_3 * self.rescale_factors            # (N, 512, 19, 19)\n",
    "                \n",
    "                #13계층 bottleneck까지만\n",
    "                seq_layer = next(layer.children())\n",
    "                for seq_n in range(4):\n",
    "                    x = seq_layer[seq_n](x)\n",
    "                    if seq_n==0:\n",
    "                        f_maps.append(x)\n",
    "                continue\n",
    "                \n",
    "            x = layer(x)\n",
    "            print(\"size : {0}, number = {1}\".format(x.size(), n))\n",
    "            if n==16:\n",
    "                f_maps.append(x) \n",
    "                \n",
    "        for extra_layer in self.extra_layers:\n",
    "            x = extra_layer(x)\n",
    "            \n",
    "            f_maps.append(x)\n",
    "            \n",
    "        cls = []\n",
    "        loc = []\n",
    "        for f_map, cls_layer, loc_layer in zip(f_maps,self. cls_layers, self.loc_layers):\n",
    "            output_cls = cls_layer(f_map)\n",
    "            output_loc = loc_layer(f_map)\n",
    "            \n",
    "            cls.append(output_cls.permute(0, 2, 3, 1).contiguous())\n",
    "            loc.append(output_loc.permute(0, 2, 3, 1).contiguous())\n",
    "            #cls.append(output_cls)\n",
    "            #loc.append(output_loc)\n",
    "            \n",
    "        cls = torch.cat([o.view(o.size(0), -1) for o in cls], 1)\n",
    "        loc = torch.cat([o.view(o.size(0), -1) for o in loc], 1)\n",
    "\n",
    "        loc = loc.view(loc.size(0), -1, 4)\n",
    "        if self.state == \"Train\":\n",
    "            cls = cls.view(cls.size(0), -1, self.n_class)\n",
    "        else:\n",
    "            cls = self.softmax(cls.view(cls.size(0), -1, self.n_class))\n",
    "            \n",
    "            \n",
    "        return cls, loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ded7bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=SSD(backbone)\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
